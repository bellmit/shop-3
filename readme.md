# Java开源项目demo--电商秒杀
## 使用的框架以及模块
spring boot 作为基础框架

数据库使用了mysql 因此需要导入 mysql-connect

数据库的连接池使用druid（springboot的默认数据库连接源（Java Database Connectivity，简称JDBC）是hikari，采用JPDC的意义在于对数据库连接池管理，提高效率）。相比起来druid的监控功能更为全面。

数据库管理使用的mybatis。


## 使用的注解
### 类注解

@SpringBootApplication 启动程序，记住其中隐含了三个配置

@RestController 相当于@Controller+@ResponseBody

@Service加载xxxServiceImpl类上，@Control加在xxxController上。
### 方法注解
@RequestMapping('/') 地址

@Autowired 自动装配

### 参数注解
@RequestParam 从前端穿回来的参数。

## 第一代项目整体框架

![系统架构](https://img-blog.csdnimg.cn/20210208165340741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pjejU1NjY3MTk=,size_16,color_FFFFFF,t_70)

在接入层是Controller实现的，包括了具体的与前端交互。其中对应需要返回给前端的数据，都特殊定义了VO模型。隐藏了不能返回给前端的隐私信息。

业务层是Service实现的，包括了几种业务的具体的模型，相应的接口，以及实现类。提供完善的方法供接入层调用。

数据层包括了dao和daoObject，是数据库中每个表对应的模型。

数据库采用的mysql的构架。

## 项目de功能实现与操作
### 插入mybatis-generator
遇到的第一个问题是我们希望使用mybatis-generator实现自动化，我们需要在pom中添加额外的配置。
首先需要在插件中引入mybatis-generator-maven-plugin，并且加入一些依赖。

这个方法使用于第一次完成数据库的映射，后面再进行数据库的升级和删改时候都是手工改动的。这个方法可以生成对应数据库的Mapper.xml，XXXDO和XXXDOMappwe文件，指明了属性值和相关的查询方法。

### 输入用户的id，调用数据库查询并且返回用户数据
第一个简单的实现是输入用户的id，调用数据库查询并且返回用户数据。

首先我们先在service层里面定义一个UserModel类，其中存放了用户模型应该具有的属性以及@Getter@Setter。并且设计一个接口UserService，接口中是User模型具有方法。在Impl中，设计接口的实现类UserServiceImpl，继承接口，并且类上使用注解@Service。

在业务层中我们需要区分xxxModel和xxxDataObjcet的区别。后者是数据库中原生的，而Model是我们在后续业务处理中真正需要使用的模型。两者可能需要一些转化。在业务层我们会执行一些复合的数据库操作，这里要使用@Transactional注解将函数声明为一个事务。这个注解是有一定的使用范围限制的。[@Transactional注解的使用范围](https://blog.csdn.net/CSDN_WYL2016/article/details/106767583)

在接入层中userController使用@RequestMapping('\get')实现一个函数逻辑，调用了select语句，返回查询的UserMode。但是这个UserMode中含有一些不应该给前端的用户信息，比如用户密码等。因此，我们需要额外设计一个UserVO模型，是返回给前端的信息。我们将UserMode传入UserVO中，并且添加上一些成功与否的内容和错误码整合为CommonReturnType的类型，返回给前端。CommonReturnType除了包含了Object类型以为，还额外附加了一个字段表示正确与否，如果错误会触发报错。

### 用户注册
在UserController类中的getopt函数，我们模拟了发短信进行注册的流程。我们随机生成了一个随机数作为验证码，并且采用`httpServletRequest.getSession().setAttribute(telephone, otpCode);`的方式将验证码和手机号进行了绑定，当然更好的方法是采用redis这类KV缓存。这个是一个可以升级的点。然后在register函数中，我们对比填入的验证码和session中的验证码是否一致。如果一致，我们往UserModel里面存入数据即可。这里可能出现跨域请求的问题。

在数据库的设计层面，我们设计了两张表一张是用户表存储用户相关的信息。另外一张是用户密码表，关联了User_id，存入了加密后的密码。这是为了用户安全考虑。

### 用户登录
用户登录的思想也是类似的，更为典型的体现了设计的思路。首先我们需要在UserService中定义LoginValidate这个抽象函数，并且在Impl中实现。实现的方法需要与UserMapper打交道，从数据库中实现读取对应telephon的UserDO和UserPasswordDO然后拼接成UserModel。在完成密码比对后返回给上层的UserModel。UserController会在httpServletRequest中保存会话信息。

### 优化校验规则
引入了新的依赖hibernate-validator，这包中有新的注解包括@NotBlank,@Max,@Min等，这些注解可以直接加载Model上避免了我们函数逻辑里面复杂的判断。


由于我们希望返回具体的错误，我们首先定义一个ValidationResult类，包含了一个布尔逻辑和一个map存放了错误的信息。实现类ValidatorImpl是一个完善，往map里面存放了错误的原因。

### 错误返回机制
将后端的错误返回给前端。首先我们定义了接口CommonError，包含方法获取错误码和错误信息以及填入错误信息。然后这个接口的实现类是一个枚举类EmBusinessError，这个枚举类中定义了int/String类型的code和Msg

这部分逻辑也是在BusinessException类中实现的。这个类首先继承了Exception类，然后继承了我们自定以的接口CommonError。而接口的是一个实现类是一个枚举类，枚举类中包括的错误码和错误信息。这样在BusinessException类中实例对象是CommonError（因为是一个接口，其实相当于是自己定义的枚举类EmBusinessError），然后可以调用CommonError的方法，包括set和get等。在遇到错误的时候可以调用BusinessException中的静态方法create创建返回给前端的错误代码。

### 商品的创建与展示
我们希望实现添加产品和展示展品。这个部分与前面非常的类似了，依然是借助数据库做好映射，生成了ItemDO和Mapper。这里同样是设计了两张表，一张是用户信息表，一张是用户库存表。这是为了以后的性能考虑。因为在用户下单的场景中，扣减商品的库存数量是需要加锁的。采用一个单独的表维护库存量可以最大程度降低加锁带来的性能瓶颈。

设计ItemService的接口，以及其实现类ItemServiceImpl用于与数据库等交互实现较为复杂的业务逻辑。创建任务中，控制层给业务层传入一个model，业务层中首先对model进行验证，`ValidationResult result = validator.validate(itemModel);`验证无误以后，转化为DO和stockDO模型存入数据库，并且从数据库中再进行一次查找取得Model然后返回。Controller需要将ItemModel转换为前端的ItemVO。整个函数需要配合配合注解@RequestMapping和@ResponseBody。

### 下单业务的创建
我们希望完成用户对商品的下单功能。我们首先设计了一个order数据库，用于存放订单的相关信息，包括了订单id，下单商品，下单人和下单价格等。这里需要特别注意的是订单ID的设计，订单的ID都是具体特殊含义的，因此我们额外的使用了一个数据库实现生成订单ID。前6位是时间，中间的是自增的，最后是分库分表标识。

用户进行下单时，首先需要检测用户的登录情况，方法是借助`Boolean isLogin = (Boolean) httpServletRequest.getSession().getAttribute("IS_LOGIN");`，如果判断正确，同样从httpServletRequest中获得用户的状态。然后调用OrderImpl中的方法，传输用户信息和产品信息。

OrderServiceImpl中的函数是最难的，这个函数是一个事务，开启@Transactional注解。我们需要先完成商品信息和用户信息的检查。然后我们需要落单减库存的操作，这是一个单独的函数。并且这个函数是在Item内的，我们需要在操作的过程中加锁实现减库存，并且通过update返回的影响数据库中的行数来判断是否成功减库存。然后再生成流水号，这是一个单独的事务，也就是说即使调用该事务的事务失败回滚了，这个事务也不应该回滚。同时我们需要考虑清楚订单号这个业务是并发类可能很大的，并且是一个危险的查询，自增，存入的非原子操作，我们需要用synchronized保护起来。同样的，增加销量也是一样的需要保护的操作。

### 促销业务
促销业务是单独的，首先需要有一个模型，因为促销业务需要有促销价格，促销时间等。促销业务本身是没有controller的，但是在order时候我们需要判断，并且我们在展示商品时候也是需要展示促销信息的。因此促销信息会与商品模型耦合。在商品的模型里，我们额外添加了一个PromoModel。在从数据库读入ItemDO转成ItemModel时候，需要检测下当前商品是不是存在促销的，如果是，需要得到促销模型添加到商品属性里。在下单时候，会从前端获取一个promoid如果是2表示正在促销，在order时候会按照促销价格下单。

## 项目升级
### 云端部署
我们的目标是实现一个完成较为完整后端方案，因此我们需要将程序放在服务器上。目前的服务器是阿里云的服务器ESC，系统是centOS7.9。在服务器的配置上，首先安装了宝塔面板。很方便的安装了一些环境，包括MySQL+MariaDB，redis和apache环境。然后从下载了Java的JDK15的rpm格式，接着xShell和Xftp上传到服务器进行安装。对于本地的数据库，导出SQL语句在宝塔上重放即可。然后我们需要把本地的程序达成jar包上传到服务器，借助maven的package插件实现。

### 外挂配置文件和编写deploy脚本
在运行过程中，我们可以在服务器上cd到\www\myshop文件夹下执行`java -jar myshop.java`执行，但是这个过程无法在后台完成。因此我们希望编写一个deploy脚本。并且由于我们可能会更改一些端口等信息，我们还希望有一个额外的`application.properties`实现一些配置。比如修改端口，修改数据库接口`127.0.0.1:3036`等。在deploy.sh中我们使用命令`nohup java XXX(VM配置) -jar myshaop.jar --spring.config.addition-location=application.properties`。

在后台的启动采用`./deply.sh &`，可以启动并且把信息打印到了nohup.out

### 使用jmeter进行压测
从官网下载jmeter，运行bat文件进行压测。这里我们需要注意的几个点在于我们使用的默认内嵌Tomcat配置`spring-confuguration-metadata`，最大等待队列长度`server.tomcat.accept-count = 100`，最大可连接数`max-connecrion=8192`, 最大工作线程数`max-threads=200`,最小工作线程数`min-spare-threads=10`。我们可以修改这些数值提高交互能力。并且我们希望定制化Tomcat开发，包括设置`keepAliveTimeOut`在多少时间以后端来keepalive，以及`maxKeepAliveRequests`多少次请求以后连接失效。这样可以保证我们的连接不会被恶意攻击，并且提高效率。

在jmeter的使用中，我们关注的数据是请求平均处理时间和tps。

### 发现并发容容量问题
可以使用`pstree -p pid | wc -l`查看java进程一共维护了多少线程。用`top -H`命令可以查看CPU的使用情况，主要关注`us`是用户进程占用的cpu时间，`sy`内核进程占用的CPU。以及`load average`这个很重要，反应了CPU的负载强度。

我们修改默认的tomcat 的线程参数认最大等待队列为1000，默认最大可连接数为10000，默认最大工作线程数为800，默认最小工作线程数为100。

*需要明确，并不等待队列和最大线程是越大越好的。等待队列会收到内存的限制，并且大量的出队入队操作会消耗cpu；线程数的切换时需要消耗cpu的，太频繁的线程消耗也是会影响系统的性能的*

对于没有通过spring boot暴露的参数，比如keepaliva参数这类的，也可以额外的定制。
具体使用`WebServerFactoryCustomizer<ConfigurableServletWebSevere>`。设置为长连接，在30s或者10000个请求以后断开，减少客户端和服务器的连接请求次数，避免重复建立连接，提高性能。这里使用的时http1.1的长连接。

### 分布式模型
之前的模型中全部的压力都是加在了一台服务器，我们希望设置多台服务器来缓解压力。比如设置一个服务器利用nginx实现反向代理，和负载均衡。两台服务器作为执行服务器，运行java逻辑，一台服务器作为一个数据库，执行查询。

#### nginx服务器
1. 首先我们利用了openresty，这时个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。具有比较好的集称性。
2. 使用了反向代理和负载均衡，将请求采用轮询的方式均匀的分配给两个服务器。
3. 优化静态资源。对于html类的请求，我们把这类请放置在距离用户最近的nginx服务器上。直接从本地读取。
4. 另外，openresty还集称了lua的脚本，我们还可以利用lua脚本或者nginx 的缓存，优化对热点数据的查询。

#### jar服务器
两台jar服务器部署了我们的java的程序，执行我们对于动态资源的查询。

#### 数据库服务器
部署了mysql（mariaDB，相当于一个开源分支）和redis的数据库。主要是用于提供查询服务。

#### RocketMq服务器
mq服务器其实可以和数据库服务器放在一起。但是由于使用的alibaba开源的rocketMq这个框架对于jdk1.8的支持比较好。因此单独放在了一台服务器上。

### nginx服务器上的优化
nginx服务器与后端的连接改为长连接，反向代理+负载均衡。这样与前后端都是长连接。

nginx高性能的原因：
1. epoll多路复用：正常的javaBIO模型，阻塞模型。当客户端与服务器建立连接之后，通过Socket.write()向服务器发送数据，只有当数据写完之后，才会发送。如果当Socket缓冲区满了，那就不得不阻塞等待；而linux的select模型，对监听一定数量的客户端，以但客户端变动就唤醒自己，然后遍历连接寻找发生改变的连接，执行IO；而epoll模型，在这个基础上增加了回调函数，一旦某个连接发生变化，直接执行回调函数。

2. master-worker进程模型
nginx有两个进程一个是master，一个是worker，其中master是worker的父进程。客户端的请求会被worker受理，多个worker采用抢占的方法获得处理权。如果某个worker挂了，master会感受到，然后另外起一个新的worker替代。这也是可以平滑重启的原因。由于worker进程是单线程的，因此没有阻塞的情况下效率很高。而epoll避免了阻塞。

3. 协程机制
更进一步的，协程是一种更小的线程，这个的切换不需要cpu的参与，依附于内存模型。以但遇到阻塞，nginx会剥夺执行权力，交给其他的协程。因此不需要加锁。

### 分布式会话
一般的分布式会话有两种思路，一种是基于cookie传输sessionid，另外是基于token传输类似sessionid。

对比：
cookie存储在客户端的浏览器上，session数据存储在服务器上。相对安全上cookie差。单个cookie的大小4k。cookie是在第一次请求时候，服务器将一些用户信息打包成cookie然后保存在浏览器等。下次再使用时候会携带cookie去访问服务器。session是会在第一次请求时候生成一个token，然后这个token 存储在服务器中。

采用了token的方法，可以利用类似雪花算法生成一个UUID作为session 的唯一登录凭证token。然后将token作为key，usermodel作为val存入redis服务器。并且是需要设置超时时间的。将token返回给前端，被存储在localstorage中。下单时候，需要验证状态，带上这个token拼接成网址。这样从后端就可以利用传入的token得到用户的情况。

### 查询优化
我们采用多级缓存的方法提高查询的效率。这里的查询主要是对于商品来说的。首先我们使用本地缓存，在两个jar服务器层面进行拦截。再然后是数据库服务器上的redis缓存，最后是mysql查询。并且逐级将得到的数据存进来。
#### 本地热点缓存的特点
在本地缓存，不需要经过网络IO，生命周期不会很长。比redis短很多。
1. 存放热点数据
2. 脏读非常不敏感，因此我们这个无法进行实时查询的，需要对脏读不敏感。比如展示给用户的商品销量等。
3. 本地缓存需要内存可用

使用谷歌提供的Guava cache，可以控制大小和超时时间；可配置lru策略；线程安全的;

具体的配置就是设置了最大100个key，超了以后按照LRU策略移除，并且设置一个比较短的过期时间，比如60s。

#### Nginx Proxy Cache缓存
既然可以在服务器上进行缓存，我们不如把缓存推的距离用户更近。也就是在nginx服务器上执行相关操作。提供了一个nginx proxy cache。可以声明一个空间进行存储。利用内存存储键，在文件系统中去读取具体的内容。
1. nginx反向代理前置
2. 依靠文件系统存索引级别的文件，请求到来以后，只需要查看对应的文件在不在即可。
3. 依靠内存缓存文件地址（key），具体的文件还是存在文件系统中

实验结果表明这个策略并不好，因为我们实际上文件系统还是在磁盘上（NAS）。效率不如在本地热点缓存好。虽然减少了一定的网络I/O，但是磁盘I/O并没有内存快，得不偿失，所以不建议使用。

#### nginx lua
基于内存的缓存策略。lua脚本是挂载在nginx处理的请求，worker进程的启动，内容输出等位置的。
1. lua协程机制
2. nginx协程机制，发生阻塞以后会返回线程。
3. 有lua的插载点

* 协程机制依附于线程的内存模型，切换开销小
* 遇阻塞即归还执行权，代码同步
* 无需加锁

nginx的每一个worker进程都是在epoll或者kqueue这种事件模型上，封装成一个协程。完全不会阻塞worker进程，都是借助协程完成的。如果某个协程完成执行需要等待，会放弃自身，然后把socket传个worker管理，在worker被epoll通知唤醒以后，新建一个协程去执行任务。因此具体任务的执行其实由协程完成的。

nginx的每个工作进程创建了一个lua虚拟机，工作进程内的所有协程共享一个VM。每个外部请求都是通过lua协程处理，之间数据隔离。lua的代码若调用io等异步接口，协程被挂起。

Java是一个请求对应一个线程，nginx是单线程，因此请求是一个协程。
#### 使用shared dict策略
在nginx中开辟一个空间，类似map，可以从缓存中存取对象。这里需要自己编写lua脚本。

#### 使用redis+lua
直接查询redis，跨过jar服务器。如果是主从redis的化可以直接只读slave服务器。

## 交易优化之缓存库存呢
### 优化用户交易过程
用户下单的过程可能是在一个热点场景（比如考虑双十一的场景），因此我们希望优化用户下单过程，提高系统的并发处理能力。在OrderController中，系统会多次查询数据库。（获取用户实时信息，验证用户身份安全性；获取商品实时信息，验证活动正确性；下单扣减库存，需要行锁保证不冲突；增加销量生成订单等）。

* 减轻数据库的查询压力
因此我们首先利用缓存提高性能，利用redis缓存存储用户信息和商品信息。其中活动信息应该是可以修改的，要提供一个活动的紧急下架能力，清除掉redis的缓存。

* 库存行锁优化
在item_stock表中我们需要添加一个`alter table item_stock add unique index item_id_item(item_id)`。保证在查询的sql语句中可以使用唯一索引，否则会锁表。之后我们再进行扣减库存缓存化，并且异步同步数据库，保证库存数据和数据库数据的一致性保证。


为了减轻数据库的查询压力，我们可以将用户的验证等信息存储在redis上。这样就可以避免重复查询数据库。之所以把用户数据放在redis上因为用户数据一般是保持不变的不容易发生脏读。而产品信息可能是会发生变化的因此对脏读会更加的敏感。维护用户的身份信息一个过期时间为1h，而商品的过期时间为10min。

具体来说就是，定义一个活动发布函数，把参与活动的商品的库存放到redis中。然后每次decreaseOrder时候在缓存减少一个。

### 异步扣减缓存
在双十一场景下，订单扣减的带给数据库的压力也会很大。因此我们希望可以优先在缓存中进行扣减，然后异步的同步到数据库中。保证数据库与缓存的最终一致即可。首先在活动开始的时候将数据库的库存信息存入redis，然后在用户下单以后，将缓存中的库存信息同步到数据库中。这就需要用到异步消息队列--RocketMQ。

rocketMQ是基于kafka模型修改的，支持高性能高并发的分布式消息中间件。典型的应用场景包括：分布式事务，异步解耦等。

一个mq队列，其中包括了produceer和consumer。进行decreas操作时候，我们首先对redis内的库存扣减。如果扣减成功，准备开始执行异步同步工作，把相关的消息发送给mq。如果mq发送消息成功，我们返回下单成功。否则需要执行回滚，redis加1，返回下单失败。这样数据库最周可以接收到相关的消息，完成异步扣减。mq的consumer函数在收到请求以后，在数据库中进行修改。

但是这样存在问题，如果消息发送失败只能回滚消息，并且数据库扣减失败的情况是无法返回的。核心问题在于，外部是一个事务，这里本质也是一个事务，但是redis和mq都不是事务。没办法保持一致的回滚。

### 一致性事务
ACID（强一致性） 
CAP理论：一致性，可用性，分区容忍性 ：我们需要在强一致性和可用性之间做出选择。因此我们一般牺牲强一致性，换取可用性。

BASE（最终一致）：基础可用，软状态，最终一致。

我们的业务是可以容忍一定的不一致性，只要要求最终一致就可以。

### RMQ事务型消息
异步消息发送失败，扣减操作失败，下单事务无法正确回补。缺少缓存库存的操作是一个什么样的状态。

我们使用RocketMq的事务型消息。消息会被发送到消息队列里面，但是消息是prepared的状态，broker会接受到消息，但是不会给消费者消费。prepared的消息会执行`TransactionListener`的`executeLocalTransaction`方法，根据执行结果，改变事务型消息的状态，让消费端消费或是不消费。

在producer中我们有一个`transactionAsyncReduceStock`这个方法会被直接调用，并且利用传入的参数，执行`transactionMQProducer.sendMessageInTransaction(message, argsMap);`方法，这个方法会返回结果表明事务成功与否，然后我们根据返回的结果进行对应的操作。

### 操作流水和售罄标志
由于可能在creatorder内部出现错误，导致没有返回消息。这样消息队列的事务就会进入UNKnown状态。我们需要根据一个操作流水复原出来之前的操作，合理的处理消息。

我们设置了一个操作流水，状态1表示初始化，2表示已经下单成功，3表示回滚。这样我们可以根据数据库中的操作流水来复原出来未处理完的消息的正确状态。

并且为了避免太多的操作流水，设置了一个售罄的标志位，首先判断是否售罄，然后再初始化操作流水。

## 流量削峰
### 秒杀令牌
由于参与秒杀的人数太多，在一瞬间会有大量的流量涌入，服务器承受不住这么大的冲击，因此我们需要流量削峰。之前在我的下单业务中，我的验证和下单逻辑都是在一个函数里面。现在我们希望把这两个功能拆分开，我们采用秒杀令牌的token的方法，只有拿到了token才是经过了验证的，可以顺利下单。在前端请求下单的时候，首先请求获得令牌，在得到了令牌以后，将令牌id`promoToken`作为参数，再去请求后端的下单接口。
### 秒杀大闸
引入秒杀令牌并无法限制流量风潮，为了防止流量的浪涌冲击。我们用秒杀大闸限制了令牌的派发数量。在商品发布时候，首先得到令牌的最大数量（i.e.全部商品数量的5倍）然后再获得令牌时候首先把redis的令牌数量减一判断是否成功再继续执行。

这个方法对于商品种类少，库存少的时候还是很好的。但是如果商品数量本身很多，这个方法对系统的保护能力也有限。（使用于抢手机，只有10台，可以设置流量大闸为100.）
### 队列泄洪
在双十一等场景下，流量可能很大。前面的方法可能无法有效限流。队列泄洪的思想是让多余的请求排队等待。排队的效率有时候优于多线程并发的策略，因为避免了锁竞争和上下文的切换。比如redis的单线程模型。

因此我们使用了一个固定大小的线程数，`fixeedThreadPool`，只能处理20个请求。并且有一个blockingqueue让其他的任务等待。在creatOrder程序中拿到秒杀令牌以后，在线程池中处理下单请求。

## 防刷限流
在秒杀开始之前，会存在大量的刷新的给服务器造成压力。我们采用验证码等方式进行防范。
### 验证码生成
在CodeUtil文件中。在请求秒杀令牌之前，需要先得到验证码。在获得秒杀令牌的函数里需要先验证校验码。具体的验证码生成来源于网络。

### 限流原理
限并发：在controller 的入口和结尾给令牌。比较粗暴

令牌桶：**处理突发流量**。采用guava的库，实现上是每秒钟有一些令牌，在发放完毕以后，查询下一秒的情况，如果下一秒没有发放完成。让请求的程序进行无法打断的sleep，将下一秒的令牌预支给他。相当于是一个定时器，每秒会新生成一定数量的令牌。

漏桶算法：**平滑网络流量**。每秒只能处理一定数量的请求。无法处理突发流量。

单机限流与集群限流：集群限流会需要一些中间件作为全局的计数器，可能导致一些性能瓶颈。因此为了简单的，我们采用单机限流的策略。这个策略在负载均衡做的比较好的时候效果很不错。

接口维度是限制某个接口的流量，总维度是限制所以接口的流量。

### RateLimiter限流实现
google.guava.RateLimiter就是令牌桶算法的一个实现类。设置了初始令牌数量为200。这个算法的之所以可以处理突发在于一个神奇的操作,**某次预先支付的令牌所需等待的时间让下一次请求来实际等待**。限制了QPS保护下游的负载。每秒钟只能处理200个请求。

比如crate(5)，但是我请求10个。会预支令牌，但是下一个请求就需要等待足2s的时间。



## 核心下单模块的解读

模块**OrderController**含有4个核心的方法：`init`,` generateVerifyCode`, `generateToken`, `creatOrder`。分别是初始化，生成验证码，生成秒杀令牌，生成下单请求。其中每个方法里面还会调用实现类的具体方法。

init中初始化了一个线程池保证最多同时处理20个业务，并且定义了令牌桶处理流量浪涌。

首先是获取验证码的环节，这里会包括对于用户属性的检查。然后是生成秒杀令牌，这里先验证了验证码的正确性，然后调用子函数`generateSecondKillToken`这个函数包括了对于商品售罄的检查、商品活动的检查，以及对redis中的秒杀大闸数量的验证，最后将针对用户和商品的token存入redis设置过期时间5分钟。

在核心的`creatOrder`函数中，首先进行rateLimit限流的判断。然后再次验证用户的有效性，校验秒杀令牌是否正确。之后进入核心的一步，在线程池里执行操作：
1. 初始化流水
2. 执行RMQ的事务型消息，调用`mqProducer.transactionAsyncReduceStock`

事务型消息会发送消息`result = transactionMQProducer.sendMessageInTransaction(message, argsMap);`其中msg是真正的消息，希望传递给数据库的；args是事务型消息会使用的参数。这个方法会将参数传递到我们之前定义的`transactionMQProducer`中执行`executeLocalTransaction`方法。这个方法在解析了传输的信息以后会调用`orderService.createOrder`方法开始实际上创建订单。

这个实例方法`orderService.createOrder`会
1. 首先在缓存中查询商品（查询不到就去sql中，然后放入redis并设置过期10分钟）的合法性。
2. 然后执行减库存操作`itemService.decreaseStock`这个方法会在redis中先扣减缓存。
3. 之后生成一个订单所需的信息，价格，交易流水号等。
4. 然后设置操作流水行为，设置为2，表示redis已经扣减。
5. 将ordermodel返回前端

如果上述方法是成功的，返回`LocalTransactionState.COMMIT_MESSAGE;`状态，异步方法则返回true。至此完成整个流程。

## 补充知识
高并发的三个利器：限流，缓存，降级。



